<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Design principles · MathOptAI.jl</title><meta name="title" content="Design principles · MathOptAI.jl"/><meta property="og:title" content="Design principles · MathOptAI.jl"/><meta property="twitter:title" content="Design principles · MathOptAI.jl"/><meta name="description" content="Documentation for MathOptAI.jl."/><meta property="og:description" content="Documentation for MathOptAI.jl."/><meta property="twitter:description" content="Documentation for MathOptAI.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">MathOptAI.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">MathOptAI.jl</a></li><li><input class="collapse-toggle" id="menuitem-2" type="checkbox"/><label class="tocitem" for="menuitem-2"><span class="docs-label">Manual</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../manual/predictors/">Predictors</a></li><li><a class="tocitem" href="../../manual/AbstractGPs/">AbstractGPs.jl</a></li><li><a class="tocitem" href="../../manual/DecisionTree/">DecisionTree.jl</a></li><li><a class="tocitem" href="../../manual/EvoTrees/">EvoTrees.jl</a></li><li><a class="tocitem" href="../../manual/Flux/">Flux.jl</a></li><li><a class="tocitem" href="../../manual/GLM/">GLM.jl</a></li><li><a class="tocitem" href="../../manual/Lux/">Lux.jl</a></li><li><a class="tocitem" href="../../manual/PyTorch/">PyTorch</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-3" type="checkbox"/><label class="tocitem" for="menuitem-3"><span class="docs-label">Tutorials</span><i class="docs-chevron"></i></label><ul class="collapsed"><li><a class="tocitem" href="../../tutorials/student_enrollment/">Logistic regression with GLM.jl</a></li><li><a class="tocitem" href="../../tutorials/decision_trees/">Classification problems with DecisionTree.jl</a></li><li><a class="tocitem" href="../../tutorials/mnist/">Adversarial machine learning with Flux.jl</a></li><li><a class="tocitem" href="../../tutorials/mnist_lux/">Adversarial machine learning with Lux.jl</a></li><li><a class="tocitem" href="../../tutorials/pytorch/">Function fitting with PyTorch</a></li><li><a class="tocitem" href="../../tutorials/gaussian/">Function fitting with AbstractGPs</a></li></ul></li><li><input class="collapse-toggle" id="menuitem-4" type="checkbox" checked/><label class="tocitem" for="menuitem-4"><span class="docs-label">Developers</span><i class="docs-chevron"></i></label><ul class="collapsed"><li class="is-active"><a class="tocitem" href>Design principles</a><ul class="internal"><li><a class="tocitem" href="#Terminology"><span>Terminology</span></a></li><li><a class="tocitem" href="#Inputs-are-vectors"><span>Inputs are vectors</span></a></li><li><a class="tocitem" href="#Inputs-are-provided,-outputs-are-returned"><span>Inputs are provided, outputs are returned</span></a></li><li><a class="tocitem" href="#Activations-are-predictors"><span>Activations are predictors</span></a></li><li><a class="tocitem" href="#Controlling-transformations"><span>Controlling transformations</span></a></li><li><a class="tocitem" href="#Full-space-or-reduced-space"><span>Full-space or reduced-space</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../../api/">API Reference</a></li><li><a class="tocitem" href="../../release_notes/">Release notes</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Developers</a></li><li class="is-active"><a href>Design principles</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Design principles</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/lanl-ansi/MathOptAI.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/lanl-ansi/MathOptAI.jl/blob/main/docs/src/developers/design_principles.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Design-principles"><a class="docs-heading-anchor" href="#Design-principles">Design principles</a><a id="Design-principles-1"></a><a class="docs-heading-anchor-permalink" href="#Design-principles" title="Permalink"></a></h1><p>This project is inspired by two existing projects:</p><ul><li><a href="https://github.com/cog-imperial/OMLT">OMLT</a></li><li><a href="https://github.com/Gurobi/gurobi-machinelearning">gurobi-machinelearning</a></li></ul><p>OMLT is a framework built around <a href="https://pyomo.org">Pyomo</a>, and gurobi-machinelearning is a framework build around gurobipy.</p><p>These projects served as inspiration, but we also departed from them in some carefully considered ways.</p><p>All of our design decisions were guided by two principles:</p><ol><li>To be simple</li><li>To leverage Julia&#39;s <code>Pkg</code> extensions and multiple dispatch.</li></ol><h2 id="Terminology"><a class="docs-heading-anchor" href="#Terminology">Terminology</a><a id="Terminology-1"></a><a class="docs-heading-anchor-permalink" href="#Terminology" title="Permalink"></a></h2><p>Because the field is relatively new, there is no settled choice of terminology.</p><p>MathOptAI chooses to use &quot;predictor&quot; as the synonym for the machine learning model. Hence, we have <code>AbstractPredictor</code>, <code>add_predictor</code>, and <code>build_predictor</code>.</p><p>In contrast, gurobi-machinelearning tends to use &quot;regression model&quot; and OMLT uses &quot;formulation.&quot;</p><p>We choose &quot;predictor&quot; because all models we implement are of the form <span>$y = f(x)$</span>.</p><p>We do not use &quot;machine learning model&quot; because we have support for the linear and logistic regression models of classical statistical fitting. We could have used &quot;regression model,&quot; but we find that models like neural networks and binary decision trees are not commonly thought of as regression models.</p><h2 id="Inputs-are-vectors"><a class="docs-heading-anchor" href="#Inputs-are-vectors">Inputs are vectors</a><a id="Inputs-are-vectors-1"></a><a class="docs-heading-anchor-permalink" href="#Inputs-are-vectors" title="Permalink"></a></h2><p>MathOptAI assumes that all inputs <span>$x$</span> and outputs <span>$y$</span> to <span>$y = predictor(x)$</span> are <code>Base.Vector</code>s.</p><p>We make this choice for simplicity.</p><p>In our opinion, Julia libraries often take a laissez-faire approach to the types that they support. In the optimistic case, this can lead to novel behavior by combining two packages that the package author had previously not considered or tested. In the pessimistic case, this can lead to incorrect results or cryptic error messages.</p><p>Exceptions to the <code>Vector</code> rule will be carefully considered and tested.</p><p>Currently, there are two exceptions:</p><ol><li>If <code>x</code> is a <code>Matrix</code>, then the columns of <code>x</code> are interpreted as independent observations, and the output <code>y</code> will be a <code>Matrix</code> with the same number of columns</li><li>The <code>StatsModels</code> extension allows <code>x</code> to be a <code>DataFrames.DataFrame</code>, if the predictor is a <code>StatsModels.TableRegressionModel</code>.</li></ol><p>Exceptions 1 and 2 are combined in the <code>StatsModels</code> exception, so that the predictor is mapped over the rows of the <code>DataFrames.DataFrame</code> (which we assume will be a common use-case).</p><p>We choose to interpret the rows as input variables and columns as independent observations (rather than the more traditional table-based approach where columns are the input variables and rows are observations) because Julia uses column-major ordering in <code>Matrix</code>. Another justification follows from the <a href="../../api/#Affine"><code>Affine</code></a> predictor, <span>$f(x) = Ax + b$</span>, where passing in a <code>Matrix</code> as <code>x</code> with column observations naturally leads to a <code>Matrix</code> output for <code>y</code> of the appropriate dimensions.</p><p>We choose to make <code>y</code> a <code>Vector</code>, even for scalar outputs, to simplify code that works generically for many different predictors. Without this principle, there will inevitably be cases where a scalar and length-1 vector are confused.</p><p>If you want to use a predictor that does not take <code>Vector</code> input (for example, it is an image as input to a neural network), the first preprocessing step should be to <code>vec</code> the input into a single <code>Vector</code>.</p><h2 id="Inputs-are-provided,-outputs-are-returned"><a class="docs-heading-anchor" href="#Inputs-are-provided,-outputs-are-returned">Inputs are provided, outputs are returned</a><a id="Inputs-are-provided,-outputs-are-returned-1"></a><a class="docs-heading-anchor-permalink" href="#Inputs-are-provided,-outputs-are-returned" title="Permalink"></a></h2><p>The main job of MathOptAI is to embed models of the form <code>y = predictor(x)</code> into a JuMP model. A key design decision is how to represent the input <code>x</code> and output <code>y</code>.</p><h3 id="gurobi-machinelearning"><a class="docs-heading-anchor" href="#gurobi-machinelearning">gurobi-machinelearning</a><a id="gurobi-machinelearning-1"></a><a class="docs-heading-anchor-permalink" href="#gurobi-machinelearning" title="Permalink"></a></h3><p>gurobi-machinelearning implements an API of the following general form:</p><pre><code class="language-python hljs">pred_constr = add_predictor_constr(model, predictor, x, y)</code></pre><p>Here, both the input <code>x</code> and the output <code>y</code> must be created and provided by the user, and a new object <code>pred_constr</code> is returned.</p><p>The benefit of this design is that <code>pred_constr</code> can contain statistics about the reformulation (for example, the number of variables that were added), and it can be used to delete a predictor from <code>model</code>.</p><p>The downside is that the user must ensure that the shape and size of <code>y</code> is correct.</p><h3 id="OMLT"><a class="docs-heading-anchor" href="#OMLT">OMLT</a><a id="OMLT-1"></a><a class="docs-heading-anchor-permalink" href="#OMLT" title="Permalink"></a></h3><p>OMLT implements an API of the following general form:</p><pre><code class="language-python hljs">model.pred_constr = OmltBlock()
model.pred_constr.build_formulation(predictor)
x, y = model.pred_constr.inputs, model.pred_constr.outputs</code></pre><p>First, a new <code>OmltBlock()</code> is created. Then the formulation is built inside the block, and both the input and output are provided to the user.</p><p>The benefit of this design is that <code>pred_constr</code> can contain statistics about the reformulation (for example, the number of variables that were added), and it can be used to delete a predictor from <code>model</code>.</p><p>The downside is that the user must often write additional constraints to connect the input and output of the <code>OmltBlock</code> to their existing decision variables:</p><pre><code class="language-python hljs">#connect pyomo model input and output to the neural network
@model.Constraint()
def connect_input(mdl):
    return mdl.input == mdl.nn.inputs[0]

@model.Constraint()
def connect_output(mdl):
    return mdl.output == mdl.nn.outputs[0]</code></pre><p>A second downside is that the predictor must describe the input and output dimension; these cannot be inferred automatically. As one example, this means that it cannot do the following:</p><pre><code class="language-python hljs"># Not possible because dimension not given
model.pred_constr.build_formulation(ReLU())</code></pre><p>In the context of MathOptAI, something like <code>ReLU()</code> is useful so that we can map generic layers like <code>Flux.relu =&gt; MathOptAI.ReLU()</code>, and so that we do not duplicate required dimension information in input and predictor (see the MathOptAI section below).</p><h3 id="MathOptAI"><a class="docs-heading-anchor" href="#MathOptAI">MathOptAI</a><a id="MathOptAI-1"></a><a class="docs-heading-anchor-permalink" href="#MathOptAI" title="Permalink"></a></h3><p>The main entry-point to MathOptAI is <a href="../../api/#add_predictor"><code>add_predictor</code></a>:</p><pre><code class="language-julia hljs">y, formulation = MathOptAI.add_predictor(model, predictor, x)</code></pre><p>The user provides the input <code>x</code>, and the output <code>y</code> is returned.</p><p>The main benefit of this approach is simplicity.</p><p>First, the user probably already has the input <code>x</code> as decision variables or an expression in the model, so we do not need the <code>connect_input</code> constraint, and because we use a full-space formulation by default, the output <code>y</code> will always be a vector of decision variables, which avoids the need for a <code>connect_output</code> constraint.</p><p>Second, predictors do not need to store dimension information, so we can have:</p><pre><code class="language-julia hljs">y, formulation = MathOptAI.add_predictor(model, MathOptAI.ReLU(), x)</code></pre><p>for any size of <code>x</code>.</p><h2 id="Activations-are-predictors"><a class="docs-heading-anchor" href="#Activations-are-predictors">Activations are predictors</a><a id="Activations-are-predictors-1"></a><a class="docs-heading-anchor-permalink" href="#Activations-are-predictors" title="Permalink"></a></h2><p>OMLT makes a distinction between layers, like <code>full_space_dense_layer</code>, and elementwise activation functions, like <code>sigmoid_activation_function</code>.</p><p>The downside to this approach is that it treats activation functions as special, leading to issues such as <a href="https://github.com/cog-imperial/OMLT/issues/125">OMLT#125</a>.</p><p>In contrast, MathOptAI treats activation functions as a vector-valued predictor like any other:</p><pre><code class="language-julia hljs">y, formulation = MathOptAI.add_predictor(model, MathOptAI.ReLU(), x)</code></pre><p>This means that we can pipeline them to create predictors such as:</p><pre><code class="language-julia hljs">function LogisticRegression(A)
    return MathOptAI.Pipeline(MathOptAI.Affine(A), MathOptAI.Sigmoid())
end</code></pre><h2 id="Controlling-transformations"><a class="docs-heading-anchor" href="#Controlling-transformations">Controlling transformations</a><a id="Controlling-transformations-1"></a><a class="docs-heading-anchor-permalink" href="#Controlling-transformations" title="Permalink"></a></h2><p>Many predictors have multiple ways that they can be formulated in an optimization model. For example, <a href="../../api/#ReLU"><code>ReLU</code></a> implements the non-smooth nonlinear formulation <span>$y = \max\{x, 0\}$</span>, while <a href="../../api/#ReLUQuadratic"><code>ReLUQuadratic</code></a> implements a the complementarity formulation <span>$x = y - slack; y, slack \ge 0; y * slack = 0$</span>.</p><p>Choosing the appropriate formulation for the combination of model and solver can have a large impact on the performance.</p><p>Because gurobi-machinelearning is specific to the Gurobi solver, they have a limited ability for the user to choose and implement different formulations.</p><p>OMLT is more general, in that it has multiple ways of formulating layers such as ReLU. However, these are hard-coded into complete formulations such as <code>omlt.neuralnet.nn_formulation.ReluBigMFormulation</code> or <code>omlt.neuralnet.nn_formulation.ReluComplementarityFormulation</code>.</p><p>In contrast, MathOptAI tries to take a maximally modular approach, where the user can control how the layers are formulated at runtime, including using a custom formulation that is not defined in MathOptAI.jl.</p><p>Currently, we achieve this with a <code>config</code> dictionary, which maps the various neural network layers to an <a href="../../api/#AbstractPredictor"><code>AbstractPredictor</code></a>. For example:</p><pre><code class="language-julia hljs">chain = Flux.Chain(Flux.Dense(1 =&gt; 16, Flux.relu), Flux.Dense(16 =&gt; 1));
config = Dict(Flux.relu =&gt; MathOptAI.ReLU)
predictor = MathOptAI.build_predictor(chain; config)</code></pre><p>Please open a GitHub issue if you have a suggestion for a better API.</p><h2 id="Full-space-or-reduced-space"><a class="docs-heading-anchor" href="#Full-space-or-reduced-space">Full-space or reduced-space</a><a id="Full-space-or-reduced-space-1"></a><a class="docs-heading-anchor-permalink" href="#Full-space-or-reduced-space" title="Permalink"></a></h2><p>OMLT has two ways that it can formulate neural networks: full-space and reduced-space.</p><p>The full-space formulations add intermediate variables to represent the output of all layers.</p><p>For example, in a <code>Flux.Dense(2, 3, Flux.relu)</code> layer, a full-space formulation will add an intermediate <code>y_tmp</code> variable to represent the output of the affine layer prior to the ReLU:</p><pre><code class="language-julia hljs">layer = Flux.Dense(2, 3, Flux.relu)
model_full_space = Model()
@variable(model_full_space, x[1:2])
@variable(model_full_space, y_tmp[1:3])
@variable(model_full_space, y[1:3])
@constraint(model_full_space, y_tmp == layer.A * x + layer.b)
@constraint(model_full_space, y .== max.(0, y_tmp))</code></pre><p>In contrast, a reduced-space formulation encodes the input-output relationship as a single nonlinear constraint:</p><pre><code class="language-julia hljs">layer = Flux.Dense(2, 3, Flux.relu)
model_reduced_space = Model()
@variable(model_reduced_space, x[1:2])
@variable(model_reduced_space, y[1:3])
@constraint(model_reduced_space, y .== max.(0, layer.A * x + layer.b))</code></pre><p>In general, the full-space formulations have more variables and constraints but simpler nonlinear expressions, whereas the reduced-space formulations have fewer variables and constraints but more complicated nonlinear expressions.</p><p>MathOptAI.jl implements the full-space formulation by default, but some layers support the reduced-space formulation with the <a href="../../api/#ReducedSpace"><code>ReducedSpace</code></a> wrapper.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../../tutorials/gaussian/">« Function fitting with AbstractGPs</a><a class="docs-footer-nextpage" href="../../api/">API Reference »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Tuesday 20 January 2026 20:33">Tuesday 20 January 2026</span>. Using Julia version 1.12.4.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
